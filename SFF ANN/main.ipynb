{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f545353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn.functional as Encoder\n",
    "from torchvision import datasets\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa20833",
   "metadata": {},
   "source": [
    "## ANN Model & Training Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302e67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        \"\"\"X is the training input while Y is the target output.\"\"\"\n",
    "\n",
    "        # Loading PyTorch dataset,\n",
    "        self.X, self.Y = torch.load(path)\n",
    "\n",
    "        # Normalisation of pixel intensity values,\n",
    "        self.X = self.X / 255\n",
    "        self.X = self.X.view(-1, 28**2)\n",
    "\n",
    "        # One-hot encoding the target output,\n",
    "        self.Y = Y_encoded = Encoder.one_hot(self.Y, num_classes = 10).to(float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of objects in the dataset.\"\"\"\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"Returns a tuple of training input and target output.\"\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    \"\"\"The neutral network architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Creating the layer stucture and activation functions of the neutral network.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Layers,\n",
    "        self.DenseLayer_INPUT = torch.nn.Linear(784, 20)\n",
    "        self.DenseLayer_HIDDEN_1 = torch.nn.Linear(20, 20)\n",
    "        self.DenseLayer_HIDDEN_2 = torch.nn.Linear(20, 20)\n",
    "        self.DenseLayer_OUTPUT = torch.nn.Linear(20, 10)\n",
    "\n",
    "        # Activation functions,\n",
    "        self.ReLU = torch.nn.ReLU()\n",
    "        self.SoftMax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Defining the forward propagation.\"\"\"\n",
    "        X = self.DenseLayer_INPUT(X)\n",
    "        X = self.ReLU(self.DenseLayer_HIDDEN_1(X))\n",
    "        X = self.ReLU(self.DenseLayer_HIDDEN_2(X))\n",
    "        X = self.SoftMax(self.DenseLayer_OUTPUT(X))\n",
    "\n",
    "        return X\n",
    "\n",
    "def TrainModel(training_data, neural_network, n_epochs = 10):\n",
    "\n",
    "    # Utilisation of CUDA if possible,\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f'CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('CUDA is not available. Using CPU.')\n",
    "\n",
    "    neural_network.to(device)\n",
    "\n",
    "    # Stochastic Gradient Descent (SGD) as optimiser,\n",
    "    optimiser = SGD(neural_network.parameters(), lr = 0.01)\n",
    "\n",
    "    # Cross-Entropy loss function,\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    epochs = np.arange(start = 1, stop = n_epochs, step = 1)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_loss = []\n",
    "        stopwatch_start = time.time()\n",
    "        for i, (X, Y) in enumerate(training_data):\n",
    "\n",
    "            # Move data to selected device,\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            # Back propagation,\n",
    "            optimiser.zero_grad() \n",
    "            loss_value = loss_function(neural_network(X), Y) \n",
    "            epoch_loss.append(loss_value.item())\n",
    "            loss_value.backward(loss_value) \n",
    "            optimiser.step()\n",
    "\n",
    "        stopwatch_stop = time.time()\n",
    "        epoch_time = round(stopwatch_stop - stopwatch_start, 2)\n",
    "        epoch_avgloss = np.mean(epoch_loss)\n",
    "        losses.append(epoch_avgloss)\n",
    "        ETA = str(datetime.timedelta(seconds = (n_epochs - epoch)*epoch_time)).split(\".\")[0]\n",
    "\n",
    "        print(f'[Completed Epoch: {epoch}/{n_epochs} ︱ Time Taken: {epoch_time} secs ︱ Loss: {epoch_avgloss:.5f} ︱ ETA: {ETA} ]')\n",
    "\n",
    "    torch.save(neural_network.state_dict(), \"model.pth\")\n",
    "    return np.array(epochs), np.array(losses)\n",
    "\n",
    "def AssessModel(test_data, neural_network):\n",
    "\n",
    "    X_test = test_data[:][0]\n",
    "    Y_test = test_data[:][1]\n",
    "    Yhat_test = neural_network(X_test)\n",
    "\n",
    "    correct_counter = 0\n",
    "    incorrect_counter = 0\n",
    "    for Y, Yhat in zip(Y_test, Yhat_test):\n",
    "        if Yhat.argmax() == Y.argmax():\n",
    "            correct_counter += 1\n",
    "        else:\n",
    "            incorrect_counter += 1\n",
    "\n",
    "    accuracy = correct_counter/(correct_counter + incorrect_counter)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0cb0e4",
   "metadata": {},
   "source": [
    "## Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4190217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prithvi\\AppData\\Local\\Temp\\ipykernel_16660\\1536117356.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = self.SoftMax(self.DenseLayer_OUTPUT(X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Completed Epoch: 1/25 ︱ Time Taken: 9.16 secs ︱ Loss: 1.93788 ︱ ETA: 0:03:39 ]\n",
      "[Completed Epoch: 2/25 ︱ Time Taken: 10.22 secs ︱ Loss: 1.59070 ︱ ETA: 0:03:55 ]\n",
      "[Completed Epoch: 3/25 ︱ Time Taken: 8.62 secs ︱ Loss: 1.57064 ︱ ETA: 0:03:09 ]\n",
      "[Completed Epoch: 4/25 ︱ Time Taken: 8.74 secs ︱ Loss: 1.55992 ︱ ETA: 0:03:03 ]\n",
      "[Completed Epoch: 5/25 ︱ Time Taken: 11.72 secs ︱ Loss: 1.55423 ︱ ETA: 0:03:54 ]\n",
      "[Completed Epoch: 6/25 ︱ Time Taken: 9.82 secs ︱ Loss: 1.55042 ︱ ETA: 0:03:06 ]\n",
      "[Completed Epoch: 7/25 ︱ Time Taken: 10.81 secs ︱ Loss: 1.54680 ︱ ETA: 0:03:14 ]\n",
      "[Completed Epoch: 8/25 ︱ Time Taken: 9.38 secs ︱ Loss: 1.54415 ︱ ETA: 0:02:39 ]\n",
      "[Completed Epoch: 9/25 ︱ Time Taken: 10.91 secs ︱ Loss: 1.54072 ︱ ETA: 0:02:54 ]\n",
      "[Completed Epoch: 10/25 ︱ Time Taken: 10.39 secs ︱ Loss: 1.53865 ︱ ETA: 0:02:35 ]\n",
      "[Completed Epoch: 11/25 ︱ Time Taken: 11.33 secs ︱ Loss: 1.53712 ︱ ETA: 0:02:38 ]\n",
      "[Completed Epoch: 12/25 ︱ Time Taken: 11.83 secs ︱ Loss: 1.53478 ︱ ETA: 0:02:33 ]\n",
      "[Completed Epoch: 13/25 ︱ Time Taken: 11.5 secs ︱ Loss: 1.53382 ︱ ETA: 0:02:18 ]\n",
      "[Completed Epoch: 14/25 ︱ Time Taken: 11.6 secs ︱ Loss: 1.53157 ︱ ETA: 0:02:07 ]\n",
      "[Completed Epoch: 15/25 ︱ Time Taken: 11.65 secs ︱ Loss: 1.52907 ︱ ETA: 0:01:56 ]\n",
      "[Completed Epoch: 16/25 ︱ Time Taken: 11.04 secs ︱ Loss: 1.52911 ︱ ETA: 0:01:39 ]\n",
      "[Completed Epoch: 17/25 ︱ Time Taken: 10.82 secs ︱ Loss: 1.52622 ︱ ETA: 0:01:26 ]\n",
      "[Completed Epoch: 18/25 ︱ Time Taken: 11.33 secs ︱ Loss: 1.52427 ︱ ETA: 0:01:19 ]\n",
      "[Completed Epoch: 19/25 ︱ Time Taken: 11.47 secs ︱ Loss: 1.52495 ︱ ETA: 0:01:08 ]\n",
      "[Completed Epoch: 20/25 ︱ Time Taken: 11.89 secs ︱ Loss: 1.52225 ︱ ETA: 0:00:59 ]\n",
      "[Completed Epoch: 21/25 ︱ Time Taken: 10.9 secs ︱ Loss: 1.52161 ︱ ETA: 0:00:43 ]\n",
      "[Completed Epoch: 22/25 ︱ Time Taken: 10.34 secs ︱ Loss: 1.52199 ︱ ETA: 0:00:31 ]\n",
      "[Completed Epoch: 23/25 ︱ Time Taken: 10.7 secs ︱ Loss: 1.52026 ︱ ETA: 0:00:21 ]\n",
      "[Completed Epoch: 24/25 ︱ Time Taken: 10.59 secs ︱ Loss: 1.52156 ︱ ETA: 0:00:10 ]\n",
      "[Completed Epoch: 25/25 ︱ Time Taken: 9.84 secs ︱ Loss: 1.51902 ︱ ETA: 0:00:00 ]\n",
      "Accuracy: 0.9319\n"
     ]
    }
   ],
   "source": [
    "# Creating and training neural network,\n",
    "TRAINING_DATASET = ConfigDataset(\"training.pt\")\n",
    "TRAINING_DATASET_LOADED = DataLoader(TRAINING_DATASET, batch_size = 5)\n",
    "NEURAL_NETWORK = NeuralNetwork()\n",
    "EPOCH_ARRAY, LOSS_ARRAY = TrainModel(TRAINING_DATASET_LOADED, NEURAL_NETWORK, n_epochs = 25)\n",
    "\n",
    "# Testing neural network,\n",
    "TEST_DATASET = ConfigDataset(\"test.pt\")\n",
    "print(\"Accuracy: \" + str(AssessModel(TEST_DATASET, NEURAL_NETWORK)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
